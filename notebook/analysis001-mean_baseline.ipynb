{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2b8ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6306ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d515095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my modules.\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "current_dir = os.path.join(Path().resolve())\n",
    "sys.path.append(str(current_dir) + '/../')\n",
    "sys.path.append(str(current_dir) + '/../input/')\n",
    "\n",
    "from codes import utils, loader\n",
    "\n",
    "import importlib\n",
    "for m in [utils, loader]:\n",
    "    importlib.reload(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c2ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../input'\n",
    "\n",
    "train_df = pd.read_csv(f'{PATH}/train.csv')\n",
    "test_df = pd.read_csv(f'{PATH}/test.csv')\n",
    "labels_df = pd.read_csv(f'{PATH}/train_labels.csv')\n",
    "submission_df = pd.read_csv(f'{PATH}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e20a85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.7240003395874013,\n",
       " 2: 0.9787757874182867,\n",
       " 3: 0.9321674165888445,\n",
       " 4: 0.7993038458273198,\n",
       " 5: 0.5463961287036251,\n",
       " 6: 0.7720519568724,\n",
       " 7: 0.7292639443076662,\n",
       " 8: 0.6143136089651074,\n",
       " 9: 0.7354614143815265,\n",
       " 10: 0.5003820358264708,\n",
       " 11: 0.6441973002801596,\n",
       " 12: 0.857458188301214,\n",
       " 13: 0.27048136514135324,\n",
       " 14: 0.7100772561337975,\n",
       " 15: 0.482978181509466,\n",
       " 16: 0.7378385261906784,\n",
       " 17: 0.6852873758383564,\n",
       " 18: 0.9505900331097716}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df['q'] = labels_df['session_id'].apply(lambda x: int(x.split('_')[-1][1:]))\n",
    "question_means = labels_df.groupby('q').correct.agg('mean').to_dict()\n",
    "question_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6220273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "labels_df['m'] = labels_df.q.map(question_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db5bfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, "
     ]
    }
   ],
   "source": [
    "# FIND BEST THRESHOLD TO CONVERT PROBS INTO 1s AND 0s\n",
    "scores = []; thresholds = []\n",
    "best_score = 0; best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0.4,0.81,0.01):\n",
    "    print(f'{threshold:.02f}, ',end='')\n",
    "    labels_df['p'] = (labels_df.m > threshold).astype('int')\n",
    "    m = f1_score(labels_df.correct.values, labels_df.p.values, average='macro')   \n",
    "    scores.append(m)\n",
    "    thresholds.append(threshold)\n",
    "    if m>best_score:\n",
    "        best_score = m\n",
    "        best_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c296e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jo_wilder\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa77a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "# The API will deliver two dataframes in this specific order,\n",
    "# for every session+level grouping (one group per session for each checkpoint)\n",
    "for (sample_submission, test) in iter_test:\n",
    "    if counter==0:\n",
    "        display(sample_submission.head())\n",
    "        display(test.head())\n",
    "        print(test.shape)\n",
    "        \n",
    "    ## users make predictions here using the test data\n",
    "    for index,row in sample_submission.iterrows():\n",
    "        q = int( row['session_id'].split('_')[-1][1:] )\n",
    "        p = int( question_means[q]>best_threshold )\n",
    "        sample_submission.loc[index,'correct'] = p\n",
    "    \n",
    "    ## env.predict appends the session+level sample_submission to the overall\n",
    "    ## submission\n",
    "    env.predict(sample_submission)\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
